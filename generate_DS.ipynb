{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "colab": {
      "name": "generate_DS.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gmazzitelli/studenti/blob/master/generate_DS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdtyA62GlVUw",
        "colab_type": "text"
      },
      "source": [
        "Inizializzation.\n",
        "\n",
        "This Cell download and intstall ROOT in python 2 environment. \n",
        "\n",
        "Runs this part of the script only when you have to init a new machine e and working space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3hGfE_u8_Ed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p APPS\n",
        "!pwd\n",
        "!cd APPS && wget https://root.cern.ch/download/root_v6.13.08.Linux-ubuntu18-x86_64-gcc7.3.tar.gz \n",
        "!cd APPS && tar -xf root_v6.13.08.Linux-ubuntu18-x86_64-gcc7.3.tar.gz\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"/content/APPS/root/lib\")\n",
        "import ctypes\n",
        "ctypes.cdll.LoadLibrary('/content/APPS/root/lib/libCore.so')\n",
        "ctypes.cdll.LoadLibrary('/content/APPS/root/lib/libThread.so')\n",
        "ctypes.cdll.LoadLibrary('/content/APPS/root/lib/libImt.so')\n",
        "ctypes.cdll.LoadLibrary('/content/APPS/root/lib/libRIO.so')\n",
        "ctypes.cdll.LoadLibrary('/content/APPS/root/lib/libNet.so')\n",
        "ctypes.cdll.LoadLibrary('/content/APPS/root/lib/libTree.so')\n",
        "ctypes.cdll.LoadLibrary('/content/APPS/root/lib/libMathCore.so')\n",
        "ctypes.cdll.LoadLibrary('/content/APPS/root/lib/libMatrix.so')\n",
        "ctypes.cdll.LoadLibrary('/content/APPS/root/lib/libHist.so')\n",
        "ctypes.cdll.LoadLibrary('/content/APPS/root/lib/libGraf.so')\n",
        "!pip install root-numpy\n",
        "ctypes.cdll.LoadLibrary('/content/APPS/root/lib/libMultiProc.so')\n",
        "ctypes.cdll.LoadLibrary('/content/APPS/root/lib/libGpad.so')\n",
        "ctypes.cdll.LoadLibrary('/content/APPS/root/lib/libGraf3d.so')\n",
        "ctypes.cdll.LoadLibrary('/content/APPS/root/lib/libTreePlayer.so')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "we6YOk--lz0r",
        "colab_type": "text"
      },
      "source": [
        "This Cell Load funcions (libraries) to retrive data from swift CYGNO server\n",
        "\n",
        "Runs this part of the script only when you have to init a new machine e and working space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsGb5OQR8jIr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q  python-swiftclient\n",
        "!pip install -q  keystoneauth1\n",
        "!pip install -q  h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np    \n",
        "import ROOT\n",
        "import root_numpy as rtnp\n",
        "! rm cygnus_lib.*; rm mylib.*\n",
        "! wget https://raw.githubusercontent.com/gmazzitelli/cygno/master/cygnus_lib.py\n",
        "! wget https://raw.githubusercontent.com/gmazzitelli/cygno/master/mylib.py\n",
        "sys.path.append('.')\n",
        "import cygnus_lib as cy\n",
        "import mylib as my\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "from scipy.optimize import curve_fit\n",
        "from scipy.stats import chisquare\n",
        "import scipy.stats as stats\n",
        "from itertools import combinations\n",
        "import math\n",
        "import os\n",
        "\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "x_resolution = y_resolution = 2048\n",
        "cy.set_atlas_style('square')\n",
        "!mkdir -p data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0Z1nMtFj0oX",
        "colab_type": "text"
      },
      "source": [
        "Generate data stream file looking for close clusters in any images: \n",
        "\n",
        "1.   download pedestal file [run_ped]\n",
        "2.   download dafa file/s [runI] from specifc location [dataSelection]\n",
        "3.   Serch for cluster with DBSCAN\n",
        "4.   save output in txt file\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7TtYehJZ4cE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "runI          = [1856] \n",
        "run_ped       = 1748 \n",
        "cimax         = 300\n",
        "cimin         = 0 \n",
        "dataSelection = 'LAB'\n",
        "rescale       = 512\n",
        "nsigma        = 1.5\n",
        "\n",
        "try:\n",
        "  fh5 = (\"run%d_mean.h5\" % (run_ped))\n",
        "  cmd = 'wget https://raw.githubusercontent.com/gmazzitelli/cygno/master/data/'+fh5+' -O ./data/'+fh5\n",
        "  os.system(cmd)\n",
        "  fh5 = (\"run%d_sigma.h5\" % (run_ped))\n",
        "  cmd = 'wget https://raw.githubusercontent.com/gmazzitelli/cygno/master/data/'+fh5+' -O ./data/'+fh5\n",
        "  os.system(cmd)\n",
        "except:\n",
        "  print (\"No Pedestal file for run %s on remote repo\" % run_ped)\n",
        "\n",
        "#########################\n",
        "\n",
        "try:\n",
        "    fileoutm = (\"./data/run%d_mean.h5\" % (run_ped))\n",
        "    m_image = cy.read_image_h5(fileoutm)\n",
        "    PedOverMax = m_image[m_image > cimax].size\n",
        "    print (\"Pedestal mean: %.2f, sigma: %.2f, over th. (%d) %d\" % \n",
        "       (m_image[m_image<cimax].mean(), \n",
        "        np.sqrt(m_image[m_image<cimax].var()), cimax,\n",
        "        (m_image>cimax).sum()))\n",
        "except:\n",
        "    print (\"No Pedestal file for run %s, run script runs-pedestals.ipynb\" % run_ped)\n",
        "    print (\"STOP\")\n",
        "\n",
        "    \n",
        "try: \n",
        "    fileouts = (\"./data/run%d_sigma.h5\" % (run_ped))\n",
        "    s_image = cy.read_image_h5(fileouts)\n",
        "    print (\"Sigma mean: %.2f, sigma: %.2f, over th. (50) %d\" % \n",
        "   (s_image[s_image<50].mean(), \n",
        "    np.sqrt(s_image[s_image<50].var()), \n",
        "    (s_image>50).sum()))\n",
        "except:\n",
        "    print (\"No Sigma file for run %s, run script runs-pedestals.ipynb\" % run_ped)\n",
        "    print (\"STOP\")\n",
        "\n",
        "#########################\n",
        "\n",
        "th_image   = np.round(m_image + nsigma*s_image)\n",
        "print (\"light over Th: %.2f \" % (th_image.sum()-m_image.sum()))\n",
        "\n",
        "    \n",
        "    \n",
        "for nRi in range(0,len(runI)):\n",
        "    try:\n",
        "        print ('Download and open file: '+cy.swift_root_file(dataSelection, runI[nRi]))\n",
        "        tmp_file = cy.swift_download_file(cy.swift_root_file(dataSelection, runI[nRi]))\n",
        "        print ('Open file: '+tmp_file)\n",
        "        f  = ROOT.TFile.Open(tmp_file);\n",
        "        print ('Find Keys: '+str(len(f.GetListOfKeys())))\n",
        "        pic, wfm = cy.root_TH2_name(f)\n",
        "        max_image = len(pic)\n",
        "        max_wfm = len(wfm)\n",
        "        print (\"# of Images (TH2) Files: %d \" % (max_image))\n",
        "        print (\"# of Waveform (TH2) Files: %d \" % (max_wfm))\n",
        "        nImag=max_image\n",
        "    except:\n",
        "        print (\"ERROR: No file %d\" % (runI[nRi]))\n",
        "        break\n",
        "\n",
        "    data_to_save = []\n",
        "    files = (\"./data/dbscan_run%d_cmin_%d_cmax_%d_rescale_%d_nsigma_%.1f_ev_%d_ped_%d.txt\" % \n",
        "                     (runI[nRi], cimin, cimax, rescale, nsigma, max_image, run_ped))\n",
        "    for iTr in range(0, max_image):\n",
        "        if iTr % 10 == 0: # pach in order overcome the problem of ROOT memory garbage\n",
        "            print ('RUN: ', runI[nRi], 'Event: ', iTr)\n",
        "            print (iTr, ' >> Close and re-Open: ', tmp_file)\n",
        "            f.Close()\n",
        "            f  = ROOT.TFile.Open(tmp_file);\n",
        "\n",
        "        image = rtnp.hist2array(f.Get(pic[iTr])).T\n",
        "\n",
        "        rebin_image     = cy.rebin(image-m_image, (rescale, rescale))  \n",
        "        rebin_th_image  = cy.rebin((th_image-m_image), (rescale, rescale))\n",
        "\n",
        "        edges           = (rebin_image > rebin_th_image) & (rebin_image < cimax)         \n",
        "        points          = np.array(np.nonzero(edges)).T.astype(float) \n",
        "        scaler          = StandardScaler()\n",
        "        X_scaled        = scaler.fit_transform(points)\n",
        "\n",
        "        dbscan          = DBSCAN(eps=0.05, min_samples = 2)\n",
        "        dbscan.fit(points)\n",
        "\n",
        "        clusters = dbscan.fit_predict(X_scaled)\n",
        "\n",
        "        for ic in range (min(dbscan.labels_), max(dbscan.labels_)):\n",
        "            ph = 0.\n",
        "            # print (\"value: \", iTr, ic, dbscan.labels_[ic], min(dbscan.labels_), max(dbscan.labels_))\n",
        "            yc = points[:,1][dbscan.labels_==ic]\n",
        "            xc = points[:,0][dbscan.labels_==ic]\n",
        "            ph, dim = cy.cluster_par(yc, xc, rebin_image)\n",
        "            width, height, pearson = cy.confidence_ellipse_par(yc,xc)\n",
        "            for j in range(0, dim):\n",
        "                x=int(xc[j])\n",
        "                y=int(yc[j])\n",
        "                #ph += rebin_image[y,x]\n",
        "                if j == 0:\n",
        "                    x0start = x\n",
        "                    y0start = y\n",
        "            x0end = x\n",
        "            y0end = y\n",
        "            data_to_save.append([iTr, ic, dim, ph, ph/dim, \n",
        "                                 x0start, y0start, x0end, y0end, width, height, pearson])\n",
        "\n",
        "    np.savetxt(files, data_to_save, fmt='%.10e', delimiter=\" \")\n",
        "    print (\"out file\", files)\n",
        "    if not cy.rm_file(tmp_file):\n",
        "        print (\">> File \"+tmp_file+\" removed\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAA8QrQ7oJWk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6ef9f189-f675-4e2c-ed67-ca91cbecae87"
      },
      "source": [
        "# outputs (.h5 are the pedestal files)\n",
        "!ls data"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dbscan_run1856_cmin_0_cmax_300_rescale_512_nsigma_1.5_ev_100_ped_1748.txt\n",
            "run1748_mean.h5\n",
            "run1748_sigma.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Shckdg9oQWr",
        "colab_type": "text"
      },
      "source": [
        "da fare:\n",
        "1.   studiarsi DBSCAN e come vengono selzionati i dati\n",
        "2.   mostrare il risultato di cluserizzazione di DBSCAN su ogni imagine (fare un debug delo script mostrando le immagini)\n",
        "2.   con panda caricare i file di output\n",
        "2.   guardarsi le varie variabili, visualizzarli, capire che significano\n",
        "3.   fare la distribuzione dei fotoni\n",
        "4.   fittarla con un esponenziale (coda del fondo) piu' gaussina (picco dei fotoni)\n",
        "5.   studiare l'andamento del picco del ferro nel tempo per i run pari tra 1856 e 2031\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRpBBbuup1-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}